{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: spaCy Parse and Network Extract\n",
    "\n",
    "**Purpose:** This script takes the text files we cleaned in part 1, and runs spaCy on them to identify named entities and token dependencies for network generation. Then it takes those spacy outputs and groups them by EIS number and runs textnet extract to generate the network files for each plan. Those extracts are saved in intermediate_files.\n",
    "\n",
    "**Setup:** requires textNet, spaCy, python, and (recommended) findpython. If you want to overwrite file outputs, set overwrite to T (we shouldn't need to do this unless changes made to network generation process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = F\n",
    "library(textNet)\n",
    "library(findpython)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare text files\n",
    "\n",
    "spacy_parse() takes a named list where each element is a different file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files <- list.files(path = \"salinasbox/clean_data/pdf_to_text_clean\", \n",
    "           pattern = \".RDS\", full.names = T)\n",
    "\n",
    "texts <- vector(mode = \"list\", length = \n",
    "                     length(files))\n",
    "\n",
    "texts <- lapply(files, function(i){\n",
    "  readRDS(i)$text\n",
    "})\n",
    "\n",
    "names(texts) <- basename(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Python environment\n",
    "\n",
    "To resolve issues with finding python binary with find_python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate)\n",
    "myenv <- conda_list(conda = \"auto\")$python\n",
    "use_condaenv(myenv[4])\n",
    "\n",
    "ret_path <- find_python_cmd(required_modules = c('spacy', 'en_core_web_lg','en_core_web_trf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parties <- c(\"Project\", \"Projects\",\n",
    "             \"Applicant\", \"Applicants\",\n",
    "             \"Permittee\", \"Permittees\",\n",
    "             \"Proponent\", \"Proponents\",\n",
    "             \"Band\", \"Bands\",\n",
    "             \"tribe\", \"tribes\",\n",
    "             \"Tribe\", \"Tribes\",\n",
    "             \"we\", \"We\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse text with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_fileloc <- paste0(\"salinasbox/intermediate_data/parsed_files/\", basename(files))\n",
    "\n",
    "parsed <- textNet::parse_text(ret_path,\n",
    "                              text_list = texts[1:2],\n",
    "                              parsed_filenames = parse_fileloc,\n",
    "                              overwrite = overwrite,\n",
    "                              ### NEW THING I CHANGED MODEL ####\n",
    "                              model = \"en_core_web_trf\",\n",
    "                              custom_entities = list(PARTIES = parties))\n",
    "\n",
    "names(parsed) <- names(texts)\n",
    "saveRDS(object = parsed, file = \"salinasbox/intermediate_data/all_parsed.RDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by EIS number\n",
    "\n",
    "Put all parts of same EIS number together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects <- vector(mode = \"list\", length = \n",
    "                     length(unique(substr(basename(files), 1, 8))))\n",
    "\n",
    "names(projects) <- unique(substr(basename(files), 1, 8))\n",
    "\n",
    "filenum = 1\n",
    "for(i in 1:length(projects)){\n",
    "  projects[[i]] <- parsed[[filenum]]\n",
    "  filenum = filenum + 1\n",
    "  while(filenum <= length(parsed) & substr(names(parsed)[filenum], 1, 8) == names(projects)[i]){\n",
    "    projects[[i]] <- rbind(projects[[i]], parsed[[filenum]])\n",
    "    filenum = filenum + 1\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract networks\n",
    "\n",
    "Better to be inclusive with entity types and remove later. See [OntoNotes documentation, page 21](https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf) for definitions.\n",
    "\n",
    "Notes:\n",
    "- \"EVENT\" doesn't have much in it but we will preserve just in case\n",
    "- \"LANGUAGE\" doesn't have much in it but sometimes \"Latino\" (??)\n",
    "- Did not keep \"MONEY\" because it appeared unreliable (sometimes was kJ, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracts <- vector(mode = \"list\", length = length(projects))\n",
    "\n",
    "keptentities <- c(\"PERSON\", \n",
    "              \"NORP\", \n",
    "              \"FAC\",\n",
    "              \"ORG\", \"GPE\", \n",
    "              \"LOC\", \"PRODUCT\", \n",
    "              \"EVENT\", \"WORK_OF_ART\",\n",
    "              \"LAW\", \"LANGUAGE\",\n",
    "              \"PARTIES\")\n",
    "\n",
    "for(m in 1:length(projects)){\n",
    "  if(overwrite ==T | !file.exists(paste0(\"salinasbox/intermediate_data/raw_extracted_networks/extract_\", names(projects)[m],\".RDS\"))){\n",
    "    extracts[[m]] <- textnet_extract(projects[[m]], \n",
    "                                     cl = 4,\n",
    "                                     keep_entities = keptentities,\n",
    "                                     return_to_memory = T,\n",
    "                                     keep_incomplete_edges = T,\n",
    "                                     file = paste0(\"salinasbox/intermediate_data/raw_extracted_networks/extract_\", names(projects)[m],\".RDS\")\n",
    "    )\n",
    "  }else{\n",
    "    print(paste0(\"file \", paste0(\"salinasbox/intermediate_data/raw_extracted_networks/extract_\", names(projects)[m],\".RDS\"),\n",
    "                 \" already exists.\"))\n",
    "  }\n",
    "  \n",
    "}\n",
    "\n",
    "saveRDS(object = extracts, file = \"salinasbox/intermediate_data/raw_extracts.RDS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
